{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b78f48b9",
   "metadata": {},
   "source": [
    "# Web Scrapping Assignment selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13e4bf",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16a2d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad959a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/763135949.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "# Lets first connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf7a8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f451ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56c481ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ba59ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b3e3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df041b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping job location\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#Scraping Company name\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#Scraping job experience\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "177a289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5350d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Contractual Hiring For Top MNC || Business Dat...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Global Indian School Education Services</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - Decision Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jana Small Finance Bank</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Programmer / Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Frost &amp; Sullivan</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Immediate opening For Data Analyst @ Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Domlur)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Contractual Hiring For Top MNC || Business Dat...   \n",
       "1                        HCL hiring For Data Analyst   \n",
       "2                              Customer Data Analyst   \n",
       "3                                   Sr. Data Analyst   \n",
       "4                    Data Analyst - Decision Science   \n",
       "5                          Programmer / Data Analyst   \n",
       "6     Immediate opening For Data Analyst @ Bangalore   \n",
       "7                             Associate Data Analyst   \n",
       "8                             Associate Data Analyst   \n",
       "9                                Senior Data Analyst   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                          Bangalore/Bengaluru, Pune   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                        Bangalore/Bengaluru(Domlur)   \n",
       "\n",
       "                              company_name experience  \n",
       "0                                TeamLease    5-8 Yrs  \n",
       "1                         HCL Technologies    3-8 Yrs  \n",
       "2                                   Oracle    1-3 Yrs  \n",
       "3  Global Indian School Education Services   6-11 Yrs  \n",
       "4                  Jana Small Finance Bank    3-8 Yrs  \n",
       "5                         Frost & Sullivan    3-7 Yrs  \n",
       "6                                TeamLease    4-6 Yrs  \n",
       "7                                    Optum    2-7 Yrs  \n",
       "8                                    Optum    1-4 Yrs  \n",
       "9                                 KrazyBee    3-5 Yrs  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'job_title':job_title, 'job_location':job_location, 'company_name':company_name, 'experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911514f7",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3633545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0cda0871",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d93fca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9f7f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cf8db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ec6126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89dacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping job location\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#Scraping Company name\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5111a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee41e3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Opportunity on Data Science_ Python with T...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>upGrad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Consultant</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>ZS Associates India Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - II</td>\n",
       "      <td>India, Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>SMARTPADDLE TECHNOLOGY PVT. LTD.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0  Job Opportunity on Data Science_ Python with T...   \n",
       "1                   Assistant Manager - Data Science   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3  Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "4                       Data Scientist/AIML Engineer   \n",
       "5  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "6                            Data Science Consultant   \n",
       "7                                  Lead ML Scientist   \n",
       "8                      Tcs Hiring For Data Scientist   \n",
       "9                                Data Scientist - II   \n",
       "\n",
       "                                        job_location  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "1                  Mumbai, Pune, Bangalore/Bengaluru   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "3  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "4  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6        Pune, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "7                        Mumbai, Bangalore/Bengaluru   \n",
       "8   Chennai, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "9     India, Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "\n",
       "                                  company_name  \n",
       "0                                Tech Mahindra  \n",
       "1                                   CitiusTech  \n",
       "2                                    Accenture  \n",
       "3  NTT DATA Business Solutions Private Limited  \n",
       "4                                       upGrad  \n",
       "5                                    Accenture  \n",
       "6                  ZS Associates India Pvt Ltd  \n",
       "7                            Fractal Analytics  \n",
       "8              TATA CONSULTANCY SERVICES (TCS)  \n",
       "9             SMARTPADDLE TECHNOLOGY PVT. LTD.  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'job_title':job_title, 'job_location':job_location, 'company_name':company_name})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6c301",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81f59bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "740626cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4f5abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b668c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31a821ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ticking on Delhi-NCR\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[2]/div[3]/div[2]/div[1]/div/div[1]/div[3]/label/p/span[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34f42532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticking on 0-3 lacs salary\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/section[1]/div[2]/div[1]/div[2]/div[2]/label/p/span[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58b707a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9575d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# Scraping job location\n",
    "location_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#Scraping Company name\n",
    "company_tags = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#Scraping job experience\n",
    "experience_tags = driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d57cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title), len(job_location), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e83f3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>4i Odc</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist, Associate</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NatWest Group</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               job_title  \\\n",
       "0                         Data Scientist   \n",
       "1        DigitalBCG GAMMA Data Scientist   \n",
       "2                         Data Scientist   \n",
       "3    Data Scientist / Chat-bot Developer   \n",
       "4                    Lead Data Scientist   \n",
       "5  Data Scientist - Predictive Analytics   \n",
       "6               Knowledge/Data Scientist   \n",
       "7                         Data Scientist   \n",
       "8                         Data Scientist   \n",
       "9              Data Scientist, Associate   \n",
       "\n",
       "                                        job_location             company_name  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "1                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "2                                   Gurgaon/Gurugram                    Optum   \n",
       "3  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "4         Noida(Sector-59 Noida)\\n(WFH during Covid)  R Systems International   \n",
       "5  Noida, Mumbai, Chandigarh, Hyderabad/Secundera...             Confidential   \n",
       "6                                        Delhi / NCR  BOLD Technology Systems   \n",
       "7                                   Gurgaon/Gurugram           Feedback Infra   \n",
       "8                                              Noida                   4i Odc   \n",
       "9                                        Delhi / NCR            NatWest Group   \n",
       "\n",
       "  experience  \n",
       "0   8-10 Yrs  \n",
       "1    2-5 Yrs  \n",
       "2    2-7 Yrs  \n",
       "3    3-7 Yrs  \n",
       "4   7-10 Yrs  \n",
       "5    1-6 Yrs  \n",
       "6    3-6 Yrs  \n",
       "7    2-4 Yrs  \n",
       "8    2-4 Yrs  \n",
       "9    2-7 Yrs  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({'job_title':job_title, 'job_location':job_location, 'company_name':company_name, 'experience':experience_required})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ead6ac8",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then \n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0440a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef03bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69c07984",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3ad8f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ff0365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb01cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Product.append(products)\n",
    "    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3b7fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36f4b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextt=driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "nextt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9216a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Product.append(products)    \n",
    "    \n",
    "\n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "174cbe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e127388",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextt=driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "nextt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55807347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags[0:20]:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "for i in Product_tags[0:20]:\n",
    "    products=i.text\n",
    "    Product.append(products)    \n",
    "    \n",
    "\n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags[0:20]:\n",
    "    price=i.text\n",
    "    Price.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e60a01c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2f70000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Clubmaster Sunglasse...</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Clubmaster Sunglasse...</td>\n",
       "      <td>₹1,049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                            Product   Price\n",
       "0           PIRASO          UV Protection Rectangular Sunglasses (52)    ₹246\n",
       "1     Singco India  Gradient, Toughened Glass Lens, UV Protection ...    ₹607\n",
       "2   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...    ₹319\n",
       "3       PHENOMENAL  UV Protection, Mirrored Retro Square Sunglasse...    ₹369\n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...    ₹359\n",
       "..             ...                                                ...     ...\n",
       "95        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹759\n",
       "96   VINCENT CHASE  by Lenskart UV Protection Clubmaster Sunglasse...  ₹1,049\n",
       "97    Singco India  Gradient, Toughened Glass Lens, UV Protection ...    ₹607\n",
       "98  ROZZETTA CRAFT  Mirrored, UV Protection Round Sunglasses (Free...    ₹359\n",
       "99   VINCENT CHASE  by Lenskart UV Protection Clubmaster Sunglasse...  ₹1,049\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'Brand':Brand, 'Product':Product, 'Price':Price})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00666a",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "You will reach to the below shown webpage:\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7988027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dc833a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f4dc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "021ab4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "532101a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e998ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "review_location=driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[2]/span[2]/span/span[3]').click()   \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22cab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c902cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Rating\n",
    "Rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "\n",
    "for i in Rating_tags:\n",
    "    ratings=i.text\n",
    "    Rating.append(ratings)\n",
    "    \n",
    "review_summary=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_summary:\n",
    "    summary=i.text\n",
    "    Review_summary.append(summary)\n",
    " \n",
    "                                                 \n",
    "Full_summary=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in Full_summary:\n",
    "    summary_f=i.text\n",
    "    Full_review.append(summary_f)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d747ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating), len(Review_summary), len(Full_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4303eb7",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ce1b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "286eca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "740b1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42d1bd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3577291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Product=[]\n",
    "Price=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f5f9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "#for i in range(0,40):\n",
    "    Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    if Product_tags == 0:\n",
    "        Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"] ')\n",
    "        \n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Product.append(products)    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n",
    "#Scraping Discount\n",
    "Dc_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in Dc_tags:\n",
    "    off=i.text\n",
    "    Discount.append(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "41399d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 32 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fe0092cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextt=driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "nextt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3e3e023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "#for i in range(0,40):\n",
    "    Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    if Product_tags == 0:\n",
    "        Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"] ')\n",
    "        \n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Product.append(products)    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n",
    "#Scraping Discount\n",
    "Dc_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in Dc_tags:\n",
    "    off=i.text\n",
    "    Discount.append(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "27386c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 67 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cb8d89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextt=driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "nextt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e87a85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "for i in Brand_tags[0:20]:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "#for i in range(0,40):\n",
    "    Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    if Product_tags == 0:\n",
    "        Product_tags = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"] ')\n",
    "        \n",
    "for i in Product_tags[0:20]:\n",
    "    products=i.text\n",
    "    Product.append(products)    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in Price_tags[0:20]:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n",
    "#Scraping Discount\n",
    "Dc_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "for i in Dc_tags[0:20]:\n",
    "    off=i.text\n",
    "    Discount.append(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8fa02b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 87 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Product), len(Price),len(Discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2a00990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹649</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹450</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>₹424</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TR</td>\n",
       "      <td>₹295</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>COOPERWINGS</td>\n",
       "      <td>₹269</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dizzler</td>\n",
       "      <td>₹479</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>₹479</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>₹619</td>\n",
       "      <td>27% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rzisbo</td>\n",
       "      <td>₹412</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand Price Discount\n",
       "0   World Wear Footwear  ₹649  56% off\n",
       "1                 BIRDE  ₹450  69% off\n",
       "2                 Xtoon  ₹424  71% off\n",
       "3                Labbin  ₹399  60% off\n",
       "4                    TR  ₹295  80% off\n",
       "..                  ...   ...      ...\n",
       "95          COOPERWINGS  ₹269  73% off\n",
       "96              Dizzler  ₹479  33% off\n",
       "97            bluemaker  ₹479  52% off\n",
       "98                Sparx  ₹619  27% off\n",
       "99               Rzisbo  ₹412  58% off\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame({'Brand':Brand, 'Price':Price, 'Discount':Discount})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e90a6",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a1c186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5693b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.myntra.com/shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "81ef2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "color=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "51924250",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "11bdc8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b3f6f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "#for i in range(0,40):\n",
    "Product_tags = driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "           \n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Description.append(products)    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5e40d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Description), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ca251329",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextt=driver.find_element(By.CLASS_NAME,\"pagination-next\")\n",
    "nextt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bf021e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand Name\n",
    "Brand_tags=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "\n",
    "for i in Brand_tags:\n",
    "    brands=i.text\n",
    "    Brand.append(brands)\n",
    "    \n",
    "# Scraping product information\n",
    "#for i in range(0,40):\n",
    "Product_tags = driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "           \n",
    "for i in Product_tags:\n",
    "    products=i.text\n",
    "    Description.append(products)    \n",
    "#Scraping Price \n",
    "Price_tags = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "for i in Price_tags:\n",
    "    price=i.text\n",
    "    Price.append(price)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "57f1d95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand), len(Description), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bec2e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Niteball II Sneakers</td>\n",
       "      <td>Rs. 9349Rs. 10999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men ZOOM WINFLO8 Running Shoes</td>\n",
       "      <td>Rs. 7880Rs. 8295(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 13295Rs. 13995(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 10799Rs. 11999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Eternity Nitro Running Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Formal Shoes</td>\n",
       "      <td>Rs. 7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Leather Sneakers</td>\n",
       "      <td>Rs. 8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women Arch Fit Slip-On Sneaker</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Leather Kitten Sandals</td>\n",
       "      <td>Rs. 7199Rs. 7999(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Women REDMOND V2 TrekkingShoe</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                     Description  \\\n",
       "0   ADIDAS Originals        Men Niteball II Sneakers   \n",
       "1               Nike  Men ZOOM WINFLO8 Running Shoes   \n",
       "2               Nike    Men React Infinity 3 Running   \n",
       "3   ADIDAS Originals   Men Leather Niteball Sneakers   \n",
       "4               Puma    Eternity Nitro Running Shoes   \n",
       "..               ...                             ...   \n",
       "95         J.FONTINI                Men Formal Shoes   \n",
       "96    Tommy Hilfiger          Women Leather Sneakers   \n",
       "97          Skechers  Women Arch Fit Slip-On Sneaker   \n",
       "98    Tommy Hilfiger    Women Leather Kitten Sandals   \n",
       "99          Columbia   Women REDMOND V2 TrekkingShoe   \n",
       "\n",
       "                          Price  \n",
       "0    Rs. 9349Rs. 10999(15% OFF)  \n",
       "1      Rs. 7880Rs. 8295(5% OFF)  \n",
       "2    Rs. 13295Rs. 13995(5% OFF)  \n",
       "3   Rs. 10799Rs. 11999(10% OFF)  \n",
       "4                     Rs. 12999  \n",
       "..                          ...  \n",
       "95                     Rs. 7490  \n",
       "96                     Rs. 8599  \n",
       "97                     Rs. 7999  \n",
       "98    Rs. 7199Rs. 7999(10% OFF)  \n",
       "99                     Rs. 7999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame({'Brand':Brand, 'Description':Description, 'Price':Price})\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562b7b3",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e5d112ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99224dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a29765b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "product.send_keys('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "efcd1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element(By.ID, 'nav-search-submit-button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5a0557fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CPU=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/ul[5]/li[10]/span/a/span').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "3ad70bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Ratings=[]\n",
    "Price=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1ad97a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    Title.append(title)\n",
    "    \n",
    "# Scraping job location\n",
    "Rating_tags = driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]')\n",
    "for i in Rating_tags[0:10]:\n",
    "    rating=i.text\n",
    "    Ratings.append(rating)\n",
    "    \n",
    "#Scraping Company name\n",
    "price_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    price_=i.text\n",
    "    Price.append(price_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6e9cc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title), len(Ratings), len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e4265b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...</td>\n",
       "      <td></td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td></td>\n",
       "      <td>80,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td></td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...</td>\n",
       "      <td></td>\n",
       "      <td>1,06,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...</td>\n",
       "      <td></td>\n",
       "      <td>1,60,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...</td>\n",
       "      <td></td>\n",
       "      <td>23,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...</td>\n",
       "      <td></td>\n",
       "      <td>41,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...</td>\n",
       "      <td></td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  MSI Modern 14, Intel i7-1195G7, 14\" FHD IPS-Le...            54,990\n",
       "1  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....            80,990\n",
       "2  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            82,990\n",
       "3  Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...            62,990\n",
       "4  Lenovo Yoga 7i 11th Gen Intel Core i7-1165G7 1...          1,06,999\n",
       "5  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...            59,990\n",
       "6  ASUS TUF Dash F15 (2022), 15.6-inch (39.62 cms...          1,60,999\n",
       "7  (Renewed) Lenovo Intel Core i7 5600U 12.5-Inch...            23,997\n",
       "8  (Renewed) HP Elitebook 840G1-i7-8 GB-2 TB 14-i...            41,690\n",
       "9  Hp Pavilion X360 11Th Gen Intel Core I7 14 Inc...            82,990"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = pd.DataFrame({'Title':Title, 'Ratings':Ratings, 'Price':Price})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3156463a",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida \n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9c1cda1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d85f3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4827c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "option=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a404bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "\n",
    "\n",
    "#designation=driver.find_element(By.CLASS_NAME,\"twitter-typeahead\")\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a64da538",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'ctas-btn-medium')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a3b4b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6acfa31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "option2=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[8]/div/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "62ce5539",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1d700644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title noclick\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "\n",
    "#Scraping Company name\n",
    "company_tags = driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#Scraping job experience\n",
    "experience_tags = driver.find_elements(By.XPATH,'//p[@class=\"body-small-l\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "473e4533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Title), len(company_name), len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dc291dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>company</th>\n",
       "      <th>Info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quality Engineer</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-8 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist- SAS Analyst</td>\n",
       "      <td>BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED</td>\n",
       "      <td>Pune, Bengaluru/Bangalore, Hyderabad/Secundera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EY GDS - Data Scientist (10-20 yrs)</td>\n",
       "      <td>EY GDS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>GLOBALLOGIC INDIA PRIVATE LIMITED</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Genpact-Data Scientist- Forecasting...</td>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Genpact - Data Scientist - Forecasting/Python/...</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>Unix, oracle, data scientists +4 more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning Algorithms (...</td>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>One97 Communications Limited</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY - Data Engineer - Data Integration/Modeling...</td>\n",
       "      <td>EY</td>\n",
       "      <td>python, sas, data science +6 more</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                   Quality Engineer   \n",
       "1                        Data Scientist- SAS Analyst   \n",
       "2                EY GDS - Data Scientist (10-20 yrs)   \n",
       "3                                     Data Scientist   \n",
       "4  Hiring For Genpact-Data Scientist- Forecasting...   \n",
       "5  Genpact - Data Scientist - Forecasting/Python/...   \n",
       "6                                     Data Scientist   \n",
       "7  Data Scientist - Machine Learning Algorithms (...   \n",
       "8                                     Data Scientist   \n",
       "9  EY - Data Engineer - Data Integration/Modeling...   \n",
       "\n",
       "                                          company  \\\n",
       "0  Optum Global Solutions (India) Private Limited   \n",
       "1  BARCLAYS GLOBAL SERVICE CENTRE PRIVATE LIMITED   \n",
       "2                                          EY GDS   \n",
       "3               GLOBALLOGIC INDIA PRIVATE LIMITED   \n",
       "4                   GENPACT India Private Limited   \n",
       "5                                         Genpact   \n",
       "6        Ericsson India Global Services Pvt. Ltd.   \n",
       "7                         Dew Solutions Pvt. Ltd.   \n",
       "8                    One97 Communications Limited   \n",
       "9                                              EY   \n",
       "\n",
       "                                                Info  \n",
       "0                                          3-8 years  \n",
       "1  Pune, Bengaluru/Bangalore, Hyderabad/Secundera...  \n",
       "2                                            2-7 Yrs  \n",
       "3                                      Not Disclosed  \n",
       "4                                              Noida  \n",
       "5              Unix, oracle, data scientists +4 more  \n",
       "6                                            2-7 Yrs  \n",
       "7                                      Not Disclosed  \n",
       "8                                              Noida  \n",
       "9                  python, sas, data science +6 more  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = pd.DataFrame({'Title':job_title,'company' :company_name, 'Info':experience_required})\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534394c",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c5175d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bipas\\AppData\\Local\\Temp/ipykernel_20080/1784537517.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\bipas\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "af08314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.ambitionbox.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d2798ea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=105.0.5195.52)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x011DDF13+2219795]\n\tOrdinal0 [0x01172841+1779777]\n\tOrdinal0 [0x01084100+803072]\n\tOrdinal0 [0x010B3FB6+999350]\n\tOrdinal0 [0x010A9B76+957302]\n\tOrdinal0 [0x010CE7FC+1107964]\n\tOrdinal0 [0x010A94B4+955572]\n\tOrdinal0 [0x010CEA14+1108500]\n\tOrdinal0 [0x010DF192+1175954]\n\tOrdinal0 [0x010CE616+1107478]\n\tOrdinal0 [0x010A7F89+950153]\n\tOrdinal0 [0x010A8F56+954198]\n\tGetHandleVerifier [0x014D2CB2+3040210]\n\tGetHandleVerifier [0x014C2BB4+2974420]\n\tGetHandleVerifier [0x01276A0A+565546]\n\tGetHandleVerifier [0x01275680+560544]\n\tOrdinal0 [0x01179A5C+1808988]\n\tOrdinal0 [0x0117E3A8+1827752]\n\tOrdinal0 [0x0117E495+1827989]\n\tOrdinal0 [0x011880A4+1867940]\n\tBaseThreadInitThunk [0x74FC6739+25]\n\tRtlGetFullPathName_UEx [0x771090AF+1215]\n\tRtlGetFullPathName_UEx [0x7710907D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20080/3375016811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moption\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"subNavListItem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#option.send_keys('Data Scientist')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moption\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    430\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=105.0.5195.52)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x011DDF13+2219795]\n\tOrdinal0 [0x01172841+1779777]\n\tOrdinal0 [0x01084100+803072]\n\tOrdinal0 [0x010B3FB6+999350]\n\tOrdinal0 [0x010A9B76+957302]\n\tOrdinal0 [0x010CE7FC+1107964]\n\tOrdinal0 [0x010A94B4+955572]\n\tOrdinal0 [0x010CEA14+1108500]\n\tOrdinal0 [0x010DF192+1175954]\n\tOrdinal0 [0x010CE616+1107478]\n\tOrdinal0 [0x010A7F89+950153]\n\tOrdinal0 [0x010A8F56+954198]\n\tGetHandleVerifier [0x014D2CB2+3040210]\n\tGetHandleVerifier [0x014C2BB4+2974420]\n\tGetHandleVerifier [0x01276A0A+565546]\n\tGetHandleVerifier [0x01275680+560544]\n\tOrdinal0 [0x01179A5C+1808988]\n\tOrdinal0 [0x0117E3A8+1827752]\n\tOrdinal0 [0x0117E495+1827989]\n\tOrdinal0 [0x011880A4+1867940]\n\tBaseThreadInitThunk [0x74FC6739+25]\n\tRtlGetFullPathName_UEx [0x771090AF+1215]\n\tRtlGetFullPathName_UEx [0x7710907D+1165]\n"
     ]
    }
   ],
   "source": [
    "option=driver.find_element(By.CLASS_NAME,\"subNavListItem\")\n",
    "#option.send_keys('Data Scientist')\n",
    "option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b4537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
